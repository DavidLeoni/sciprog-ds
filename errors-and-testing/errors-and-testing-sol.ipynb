{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "import jupman;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error handling and testing solutions\n",
    "\n",
    "* **Error handling  was** [moved to softpython](https://en.softpython.org/errors-and-testing/errors-and-testing-sol.html)\n",
    "\n",
    "According to the part of the course you are following, we will review two kinds of tests:\n",
    "\n",
    "* **Part A testing with asserts**:  [moved to SoftPython](https://en.softpython.org/errors-and-testing/errors-and-testing-sol.html#Testing-with-asserts)\n",
    "\n",
    "* **Part B testing with unittest**: read this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "\n",
    "* If it seems to work, then it actually works? _Probably not_.\n",
    "* The devil is in the details, especially for complex algorithms.\n",
    "* We will do a crash course on testing in Python\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**WARNING**: Bad software can cause losses of million $/â‚¬ or even harm people. Suggested reading: [Software Horror Stories](https://www.cs.tau.ac.il/~nachumd/horror.html)\n",
    "</div>\n",
    "\n",
    "### Where Is Your Software?\n",
    "\n",
    "As a data scientist, you might likely end up with code which is moderately complex from an algorithmic point of view, but maybe not too big in size. Either way, when red line is crossed you should start testing properly:\n",
    "\n",
    "![where is your software](img/where-is-your-software.png)\n",
    "\n",
    "\n",
    "In a typical scenario, you are a junior programmer and your senior colleague ask you to write a function to perform some task, giving only an informal description:\n",
    "\n",
    "```python\n",
    "def my_sum(x,y):\n",
    "    \"\"\" RETURN the sum of x and y\n",
    "    \"\"\"    \n",
    "    raise Exception(\"TODO IMPLEMENT ME!\")\n",
    "```\n",
    "\n",
    "Even better, your colleague might provide you with some automated tests you might run to check your function meets his/her expectations. If you are smart, you will even write tests for your own functions to make sure every little piece you add to your software is a solid block you can build upon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### even_numbers example\n",
    "\n",
    "Let's see a slightly more complex function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_numbers(n):\n",
    "    \"\"\"\n",
    "    Return a list of the first n even numbers \n",
    "    \n",
    "    Zero is considered to be the first even number.\n",
    "\n",
    "    >>> even_numbers(5)\n",
    "    [0,2,4,6,8]\n",
    "    \"\"\"    \n",
    "    raise Exception(\"TODO IMPLEMENT ME!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, if you run the function as it is, you are reminded to implement it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> even_numbers(5)\n",
    "```\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Exception                                 Traceback (most recent call last)\n",
    "<ipython-input-2-d2cbc915c576> in <module>()\n",
    "----> 1 even_numbers(5)\n",
    "\n",
    "<ipython-input-1-a20a4ea4b42a> in even_numbers(n)\n",
    "      8     [0,2,4,6,8]\n",
    "      9     \"\"\"    \n",
    "---> 10     raise Exception(\"TODO IMPLEMENT ME!\")\n",
    "\n",
    "Exception: TODO IMPLEMENT ME!\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why? The instruction \n",
    "```python\n",
    "raise Exception(\"TODO IMPLEMENT ME!\")\n",
    "```\n",
    "\n",
    "tells Python to immediatly stop execution, and signal an error to the caller of the function `even_number`. If there were commands right after `raise Exception(\"TODO IMPLEMENT ME\")`, they would not be executed. Here, we are directly calling the function from the prompt, and we didn't tell Python how to handle the `Exception`, so Python just stopped and showed the error message given as parameter to the `Exception`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Spend time reading the function text!**\n",
    "\n",
    "Always carefully read the function text and ask yourself questions! What is the supposed input? What should be the output? Is there any output to return at all, or should you instead modify _in-place_ a passed parameter (i.e. for example, when you sort a list)? Are there any edge cases, es what happens for `n=0`)? What about `n < 0` ?\n",
    "\n",
    "</div>\n",
    "\n",
    "Let's code a possible solution. As it often happens, first version may be buggy, in this case for example purposes we intentionally introduce a bug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_numbers(n):\n",
    "    \"\"\"\n",
    "    Return a list of the first n even numbers \n",
    "    \n",
    "    Zero is considered to be the first even number.\n",
    "\n",
    "    >>> even_numbers(5)\n",
    "    [0,2,4,6,8]\n",
    "    \"\"\"    \n",
    "    r = [2 * x for x in range(n)]\n",
    "    r[n // 2] = 3   # <-- evil bug, puts number '3' in the middle, and 3 is not even ..\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically the first test we do is printing the output and do some 'visual inspection' of the result, in this case we find many numbers are correct but we might miss errors such as the wrong `3` in the middle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "print(even_numbers(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, if we enter commands a the prompt, each time we fix something in the code, we need to enter commands again to check everything is ok. This is inefficient, boring, and prone to errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's add assertions\n",
    "\n",
    "To go beyond the dumb \"visual inspection\" testing, it's better to write some extra code to allow Python checking for us if the function actually returns what we expect, and throws an error otherwise. We can do so with `assert` command, which verifies if its argument is True. If it is not, it raises an `AssertionError` immediately stopping execution. \n",
    "\n",
    "Here we check the result of `even_numbers(5)` is actually the list of even numbers `[0,2,4,6,8]` we expect:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "assert even_numbers(5) == [0,2,4,6,8]\n",
    "```\n",
    "\n",
    "Since our code is faulty, `even_numbers` returns the wrong list `[0,2,3,6,8]` which is different from `[0,2,4,6,8]` so assertion fails showing `AssertionError`:\n",
    "\n",
    "```python\n",
    "---------------------------------------------------------------------------\n",
    "AssertionError                            Traceback (most recent call last)\n",
    "<ipython-input-21-d4198f229404> in <module>()\n",
    "----> 1 assert even_numbers(5) != [0,2,4,6,8]\n",
    "\n",
    "AssertionError: \n",
    "\n",
    "```\n",
    "\n",
    "We got some output, but we would like to have it more informative. To do so, we may add a message, separated by a comma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "assert even_numbers(5) == [0,2,4,6,8], \"even_numbers is not working !!\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "---------------------------------------------------------------------------\n",
    "AssertionError                            Traceback (most recent call last)\n",
    "<ipython-input-18-8544fcd1b7c8> in <module>()\n",
    "----> 1 assert even_numbers(5) == [0,2,4,6,8], \"even_numbers is not working !!\"\n",
    "\n",
    "AssertionError: even_numbers is not working !!\n",
    "\n",
    "``````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we modify code to fix bugs we can just launch the assert commands and have a quick feedback about possible errors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error kinds\n",
    "\n",
    "As a fact of life, errors happen. Sometimes, your program may have inconsistent data, like wrong parameter type passed to a function (i.e. string instead of integer). A good principle to follow in these cases is to try have the program detect weird situations, and stop as early as such a situation is found (i.e. in the Therac 25 case, if you detect excessive radiation, showing a warning sign is not enough, it's better to stop). Note stopping might not always be the desirable solution (if one pidgeon enters one airplane engine, you don't want to stop all the other engines). If you want to check function parameters are correct, you do the so called _precondition checking_.\n",
    "\n",
    "There are roughly two cases for errors,  external user misusing you program, and just plain wrong code. Let's analyize both:\n",
    "\n",
    "#### Error kind a) An external user misuses you program.\n",
    "\n",
    "You can assume whover uses your software, final users or other programmers , they will try their very best to wreck your precious code by passing all sort of non-sense to functions. Everything can come in, strings instead of numbers, empty arrays, `None` objects ... In this case you should signal the user he made some mistake. The most crude signal you can have is raising an `Exception` with `raise Exception(\"Some error occurred\")`, which will stop the program and print the stacktrace in the console. Maybe final users won't understand a stacktrace, but at least programmers hopefully will get a clue about what is happening. \n",
    "\n",
    "In these case you can raise an appropriate Exception, like [TypeError](https://docs.python.org/3/library/exceptions.html#TypeError) for wrong types and [ValueError](https://docs.python.org/3/library/exceptions.html#ValueError) for more generic errors. Other basic exceptions can be found in [Python documentation](https://docs.python.org/3/library/exceptions.html#built-in-exceptions). Notice you can also define your own, if needed (we won't consider custom exceptions in this course).\n",
    "\n",
    "**NOTE**: Many times, you can consider yourself the 'careless external user' to guard against. \n",
    "\n",
    "Let's enrich the function with some appropriate type checking:\n",
    "\n",
    "Note that for checking input types, you can use the function `type()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(\"ciao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the code for checking the [even_numbers example](#even_numbers-example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_numbers(n):\n",
    "    \"\"\"\n",
    "    Return a list of the first n even numbers \n",
    "    \n",
    "    Zero is considered to be the first even number.\n",
    "\n",
    "    >>> even_numbers(5)\n",
    "    [0,2,4,6,8]\n",
    "    \"\"\" \n",
    "    if type(n) is not int:\n",
    "        raise TypeError(\"Passed a non integer number: \" + str(n))\n",
    "    \n",
    "    if n < 0:\n",
    "        raise ValueError(\"Passed a negative number: \" + str(n))\n",
    "        \n",
    "    r = [2 * x for x in range(n)]\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pass a wrong type and see what happens:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    ">>> even_numbers(\"ciao\")\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-14-a908b20f00c4> in <module>()\n",
    "----> 1 even_numbers(\"ciao\")\n",
    "\n",
    "<ipython-input-13-b0b3a85f2b2a> in even_numbers(n)\n",
    "      9     \"\"\" \n",
    "     10     if type(n) is not int:\n",
    "---> 11         raise TypeError(\"Passed a non integer number: \" + str(n))\n",
    "     12 \n",
    "     13     if n < 0:\n",
    "\n",
    "TypeError: Passed a non integer number: ciao\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to pass a negative number - it should suddenly stop with a meaningful message: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> even_numbers(-5)\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "ValueError                                Traceback (most recent call last)\n",
    "<ipython-input-15-3f648fdf6de7> in <module>()\n",
    "----> 1 even_numbers(-5)\n",
    "\n",
    "<ipython-input-13-b0b3a85f2b2a> in even_numbers(n)\n",
    "     12 \n",
    "     13     if n < 0:\n",
    "---> 14         raise ValueError(\"Passed a negative number: \" + str(n))\n",
    "     15 \n",
    "     16     r = [2 * x for x in range(n)]\n",
    "\n",
    "ValueError: Passed a negative number: -5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, even if you ship your code to careless users, and as soon as they commit a mistrake, they will get properly notified. \n",
    "\n",
    "\n",
    "#### Error kind b): Your code is just plain wrong\n",
    "\n",
    "In this case, it's 100% your fault, and these sort of bugs should never pop up in production. For example your code passes internally wrong stuff, like strings instead of integers, or wrong ranges (typically integer outside array bounds). So if you have an internal function nobody else should directly call, and you suspect it is being passed wrong parameters or at some point it has inconsistent data, to quickly spot the error you could add an assertion:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_numbers(n):\n",
    "    \"\"\"\n",
    "    Return a list of the first n even numbers \n",
    "    \n",
    "    Zero is considered to be the first even number.\n",
    "\n",
    "    >>> even_numbers(5)\n",
    "    [0,2,4,6,8]\n",
    "    \"\"\" \n",
    "    assert type(n) is int, \"type of n is not correct: \" + str(type(n))\n",
    "    assert n >= 0, \"Found negative n: \" + str(n)\n",
    "        \n",
    "    r = [2 * x for x in range(n)]\n",
    "    \n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the function will stop as soon we call it we wrong parameters. The big difference is, this time we are assuming `even_numbers` is just for personal use and nobody else except us should directly call it. \n",
    "\n",
    "Since assertion consume CPU time, IF we care about performances AND once we are  confident our program behaves correctly, we can even remove them from compiled code by using the `-O` compiler flag. For more info, see [Python wiki](https://wiki.python.org/moin/UsingAssertionsEffectively) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**: try to call latest definition of `even_numbers` with wrong parameters, and see what happens.\n",
    "\n",
    "**NOTE**: here we are using the correct definition of `even_numbers`, not the buggy one with the `3` in the middle of returned list !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Unittest\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**NOTE**: Testing with Unittest is only done in PART B of this course\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "Is there anything better than `assert`for testing? `assert` can be a quick way to check but doesn't tell us exactly which is the wrong number in the list returned by `even_number(5)`. Luckily, Python offers us a better option, which is a complete testing framework called [unittest](https://docs.python.org/3/library/unittest.html). We will use unittest because it is the standard one, but if you're doing other projects you might consider using better ones like [pytest](https://docs.pytest.org/) (note it can also execute tests made with unittest, so if your visualstudio code for some reason doesn't work with unittest, you can try setting pytest as test framework)\n",
    "\n",
    "So let's give unittest a try. Suppose you have a file called `file_test.py` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "raw_mimetype": "text/x-python"
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "def even_numbers(n):\n",
    "    \"\"\"\n",
    "    Return a list of the first n even numbers \n",
    "    \n",
    "    Zero is considered to be the first even number.\n",
    "\n",
    "    >>> even_numbers(5)\n",
    "    [0,2,4,6,8]\n",
    "    \"\"\"    \n",
    "    r = [2 * x for x in range(n)]\n",
    "    r[n // 2] = 3   # <-- evil bug, puts number '3' in the middle\n",
    "    return r\n",
    "\n",
    "class MyTest(unittest.TestCase):\n",
    "\n",
    "    def test_long_list(self):\n",
    "        self.assertEqual(even_numbers(5),[0,2,4,6,8]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We won't explain what `class` mean ([for classes see the book chapter ](http://interactivepython.org/runestone/static/pythonds/Introduction/ObjectOrientedProgramminginPythonDefiningClasses.html)), the important thing to notice is the method definition:\n",
    "\n",
    "\n",
    "```python\n",
    "    def test_long_list(self):\n",
    "        self.assertEqual(even_numbers(5),[0,2,4,6,8]) \n",
    "\n",
    "```\n",
    "\n",
    "In particular:\n",
    "\n",
    "* method is declared like a function, and begins with `'test_'` word\n",
    "* method takes `self` as parameter\n",
    "* `self.assertEqual(even_numbers(5),[0,2,4,6,8]) ` executes the assertion. Other assertions could be `self.assertTrue(some_condition) or self.assertFalse(some_condition) `\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running tests\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "To run the tests, enter the following command in the terminal: <br/>\n",
    "<br/>\n",
    "\n",
    "``` \n",
    "python -m unittest file_test\n",
    "        \n",
    "```\n",
    "\n",
    "<div class=\"alert -alert-warning\">\n",
    "    \n",
    "**!!!!!   WARNING**: In the call above, DON'T append the extension `.py` to `file_test`    !!!!!!\n",
    "<br/>\n",
    "    \n",
    "**!!!!!   WARNING**: Still, on the hard-disk the file MUST be named with a `.py` at the end, like `file_test.py`!!!!!!\n",
    "\n",
    "</div>\n",
    "\n",
    "You should see an output like the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F\n",
      "======================================================================\n",
      "FAIL: test_long_list (__main__.MyTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_21160/3269760140.py\", line 19, in test_long_list\n",
      "    self.assertEqual(even_numbers(5),[0,2,4,6,8])\n",
      "AssertionError: Lists differ: [0, 2, 3, 6, 8] != [0, 2, 4, 6, 8]\n",
      "\n",
      "First differing element 2:\n",
      "3\n",
      "4\n",
      "\n",
      "- [0, 2, 3, 6, 8]\n",
      "?        ^\n",
      "\n",
      "+ [0, 2, 4, 6, 8]\n",
      "?        ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "jupman.show_run(MyTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see a nice display of where the error is, exactly in the middle of the list!\n",
    "\n",
    "### When tests don't run\n",
    "\n",
    "\n",
    "When `-m unittest` does not work and you keep seeing absurd errors like Python not finding a module and you are getting desperate (especially because Python has `unittest` included _by default_, there is no need to install it! ), try putting the following code at the very end of the file you are editing: \n",
    "\n",
    "```python\n",
    "unittest.main()\n",
    "```\n",
    "\n",
    "Then simply run your file with:\n",
    "\n",
    "```bash\n",
    "python file_test.py\n",
    "```\n",
    "\n",
    "In this case it should REALLY work. If it still doesn't, call the Ghostbusters. Or, better, the IndentationBusters, you're likely having tabs mixed with spaces mixed with very bad luck.\n",
    "\n",
    "\n",
    "### Adding tests\n",
    "\n",
    "How can we add (good) tests? Since best ones are usually short, it would be better starting small boundary cases. For example like `n=1` , which according to function documentation should produce a list containing zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTest(unittest.TestCase):\n",
    "\n",
    "    def test_one_element(self):\n",
    "        self.assertEqual(even_numbers(1),[0])\n",
    "        \n",
    "    def test_long_list(self):\n",
    "        self.assertEqual(even_numbers(5),[0,2,4,6,8]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call again the command: \n",
    "\n",
    "```bash\n",
    "python -m unittest file_test\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FF\n",
      "======================================================================\n",
      "FAIL: test_long_list (__main__.MyTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_21160/1413161586.py\", line 7, in test_long_list\n",
      "    self.assertEqual(even_numbers(5),[0,2,4,6,8])\n",
      "AssertionError: Lists differ: [0, 2, 3, 6, 8] != [0, 2, 4, 6, 8]\n",
      "\n",
      "First differing element 2:\n",
      "3\n",
      "4\n",
      "\n",
      "- [0, 2, 3, 6, 8]\n",
      "?        ^\n",
      "\n",
      "+ [0, 2, 4, 6, 8]\n",
      "?        ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_one_element (__main__.MyTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_21160/1413161586.py\", line 4, in test_one_element\n",
      "    self.assertEqual(even_numbers(1),[0])\n",
      "AssertionError: Lists differ: [3] != [0]\n",
      "\n",
      "First differing element 0:\n",
      "3\n",
      "0\n",
      "\n",
      "- [3]\n",
      "+ [0]\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.003s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    }
   ],
   "source": [
    "jupman.show_run(MyTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the tests we can now see there is clearly something wrong with the number 3 that keeps popping up, making both tests fail. You can see immediately which tests have failed by looking at the first two `FF` at the top of the output. Let's fix the code by removing the buggy line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_numbers(n):\n",
    "    \"\"\"\n",
    "    Return a list of the first n even numbers \n",
    "    \n",
    "    Zero is considered to be the first even number.\n",
    "\n",
    "    >>> even_numbers(5)\n",
    "    [0,2,4,6,8]\n",
    "    \"\"\"    \n",
    "    r = [2 * x for x in range(n)]\n",
    "    # NOW WE COMMENTED THE BUGGY LINE  r[n // 2] = 3   # <-- evil bug, puts number '3' in the middle\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And call yet again the command: \n",
    "\n",
    "```bash\n",
    "python -m unittest file_test\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "jupman.show_run(MyTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful, all the two tests have passed and we got rid of the bug. \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**WARNING: DON'T DUPLICATE TEST CLASS NAMES AND/OR METHODS!**\n",
    "\n",
    "In the following, you will be asked to add tests. Just add **NEW** methods with **NEW** names to the **EXISTING** class `MyTest` !\n",
    "\n",
    "</div>\n",
    "\n",
    "### Exercise: boundary cases\n",
    "\n",
    "Think about other boundary cases, and try to add corresponding tests.\n",
    "\n",
    "- Can we ever have an empty list? \n",
    "- Can `n` be equal to zero? Add a test **inside MyTest class** for its expected result.\n",
    "- Can `n` be negative? In this case the function text tells us nothing about the expected behaviour, so we might choose it now: either the function raises an error, or it gives a back something, like i.e. list of even negative numbers. Try to modify `even_numbers` and add a relative test **inside MyTest class** for expecting even negative numbers (starting from zero). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: expecting assertions\n",
    "\n",
    "What if user passes us a float like `3.5` instead of an integer? If you try to run `even_numbers(3.5)` you  will discover it works anyway, but we might decide to be picky and not accept inputs other than integers. Try to modify `even_numbers` to make so that when input is not of type `int`, raises [TypeError](https://docs.python.org/3/library/exceptions.html#TypeError) (to check for type, you can write `type(n) == int`). \n",
    "\n",
    "\n",
    "To test for it, add following test **inside MyTest class** :\n",
    "\n",
    "```python\n",
    "    def test_type(self):\n",
    "\n",
    "        with self.assertRaises(TypeError):  \n",
    "            even_numbers(3.5)                \n",
    "```\n",
    "\n",
    "\n",
    "The `with` block tells Python to expect the code inside the `with` block to raise \n",
    "the exception [TypeError](https://docs.python.org/3/library/exceptions.html#TypeError):\n",
    "\n",
    "- If `even_numbers(3.5)` actually raises `TypeError` exception, nothing happens\n",
    "- If `even_numbers(3.5)` does not raise `TypeError` exception, with raises `AssertionError`\n",
    "\n",
    "\n",
    "\n",
    "After you completed previous task, consider when the input is the float `4.0`:  in this case it might make sense to still accept it, so modify `even_numbers` accordingly and write a test for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: good tests\n",
    "\n",
    "What difference is there between the following two test classes? Which one is better for testing?\n",
    "\n",
    "```python\n",
    "class MyTest(unittest.TestCase):\n",
    "\n",
    "    def test_one_element(self):\n",
    "        self.assertEqual(even_numbers(1),[0])\n",
    "        \n",
    "    def test_long_list(self):\n",
    "        self.assertEqual(even_numbers(5),[0,2,4,6,8]) \n",
    "        \n",
    "```\n",
    "\n",
    "and\n",
    " \n",
    "```python\n",
    "class MyTest(unittest.TestCase):\n",
    "\n",
    "    def test_stuff(self):\n",
    "        self.assertEqual(even_numbers(1),[0])\n",
    "        self.assertEqual(even_numbers(5),[0,2,4,6,8])               \n",
    "        \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running unittests in Visual Studio Code\n",
    "\n",
    "\n",
    "You can run and debug tests in  Visual Studio Code, which is very handy. First, you need to set it up.\n",
    "\n",
    "1. Hit `Control-Shift-P` (on Mac: `Command-Shift-P`) and type `Python: Configure Tests`  \n",
    "\n",
    "![vscode 1 4292234](img/vscode-1.png)\n",
    "\n",
    "2. Select unittest:\n",
    "\n",
    "![vscode 2 2341234123](img/vscode-2.png)\n",
    "\n",
    "3. Select `. root directory` (we assume tests are in the folder that you've opened):\n",
    "\n",
    "![vscode 3 3142434](img/vscode-3.png)\n",
    "\n",
    "4. Select `*test*.py Python files containing the word 'test'`:\n",
    "\n",
    "![vscode 4 92383283](img/vscode-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, on the currently opened test file new labels should appear above class and test methods, like in the following example. Try to click on them: \n",
    "\n",
    "![vscode 5 8232114](img/vscode-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the bottom bar, you should see a recap of tests run  (right side of the picture):\n",
    "\n",
    "![vscode 6 2348324332](img/vscode-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TROUBLESHOOTING\n",
    "\n",
    "\n",
    "If you encounter problems running tests and have Anaconda, sometimes an easy solution can be just closing Visual Studio Code and running it from the Anaconda Navigator. You can also try updating it.\n",
    "\n",
    "\n",
    "**Running tests by console does not work:**\n",
    "\n",
    "* remember to SAVE the files before executing tests: in Windows, a file appears as not saved when its filename in the tab is written in italics; on Linux, you might see a dot to the right of the filename\n",
    "\n",
    "**Run Test label does not show up in code:**\n",
    "\n",
    "- if you see red squiggles in the code, most probably syntax is not correct and thus no test will get discovered ! If this is the case, fix the syntax error, SAVE, and then tell Visual Studio to discover test. \n",
    "- you might also try  _Right click->Run current Test File_. \n",
    "- try [selecting another testing framework](#Running-unittests-in-Visual-Studio-Code) , try pytest, which is also capable to discover and execute unittests.\n",
    "- if you are really out of luck with the editor, there is always the option of running tests from the console. \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Spend time using the console !!!!**\n",
    "\n",
    "During exams VSCode testing might not work, so please be prepared to use the console\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional programming\n",
    "\n",
    "In functional programming, functions behave as mathematical ones so they always take some parameter and return new data without ever changing the input. They say functional programming is easier to test. Why? \n",
    "\n",
    "**Immutable data structures**:  all data structures are (or are meant to be) immutable -> no code can ever tweak your data, so other developers just cannot (should not) be able to inadvertently change your data. \n",
    "\n",
    "**Simpler parallel computing**:  point above is particularly inmportant in parallel computation, when the system can schedule thread executions differently _each_ time you run the program:  this implies that when you have multiple threads it can be very very hard to reproduce a bug where a thread wrongly changes a data which is supposed to be exclusively managed by another one: it might fail in one run and succeed in another just because the system scheduled differently the code execution! Functional programming frameworks like [Spark](https://spark.apache.org) solve these problems very nicely.\n",
    "\n",
    "**Easier to reason about code**: it is much easier to reason about functions, as we can use standard equational reasoning on input/outputs as traditionally done in algebra. To understand what we're talking about, you can see these slides: [Visual functional programming](https://docs.google.com/presentation/d/1hTHty5aML9WDDTvkflvvdGDh0AfZwV_8ZEr10-rUPVA) (will talk more about it in class)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0385398",
   "metadata": {
    "format": "text/html"
   },
   "source": [
    "<a  class=\"jupman-sol jupman-sol-toggler\" \n",
    " onclick=\"jupman.toggleSolution(this);\" \n",
    " data-jupman-show=\"Show solution\" data-jupman-hide=\"Hide\">Show solution</a><div class=\"jupman-sol jupman-sol-code\" style=\"display:none\">  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44247254",
   "metadata": {
    "format": "text/html"
   },
   "source": [
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
